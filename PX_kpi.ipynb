{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PX_kpi.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPHp3LQbAV4b960jJQpYR18",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adarshr00711/Stock-price-prediction/blob/master/PX_kpi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "FN1nFMO2C1Po",
        "outputId": "d7e9bee4-f042-4ccf-ab4e-02d196349bd8"
      },
      "source": [
        "#dta read\n",
        "from azureml.core import Run\n",
        "import argparse\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pyodbc\n",
        "# dataset object from the run\n",
        "parser=argparse.ArgumentParser('Data_read')\n",
        "parser.add_argument('--output',type=str)\n",
        "args = parser.parse_args()\n",
        "output = args.output\n",
        "df.head()\n",
        "os.makedirs(output, exist_ok=True)\n",
        "output_path = output + \"/agg_input.csv\"\n",
        "print(output_path)\n",
        "df.to_csv(output_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-cc7e18de2b2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#dta read\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'azureml'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrDlY1jKiPgU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 943
        },
        "outputId": "b189b805-d517-4356-c05c-2b95ad6b91fd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \"\"\"\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    111\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m       \u001b[0muse_metadata_server\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_metadata_server\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m       ephemeral=ephemeral)\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server, ephemeral)\u001b[0m\n\u001b[1;32m    290\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dfs-auth-dance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m           \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll7a_u2h5rAe"
      },
      "source": [
        "\n",
        "\n",
        " \n",
        "#feature engineering\n",
        "\n",
        "numeric_features = ['gap']\n",
        "numeric_transformer = StandardScaler()\n",
        "\n",
        " \n",
        "\n",
        "\n",
        " \n",
        "categorical_features = ['month_flight']\n",
        "categorical_transformer = OneHotEncoder()\n",
        "\n",
        " \n",
        "\n",
        "\n",
        " \n",
        "preprocessor = ColumnTransformer(\n",
        "transformers=[\n",
        "(\"num\", numeric_transformer, numeric_features),\n",
        "(\"cat\", categorical_transformer, categorical_features)\n",
        "]\n",
        ")\n",
        "\n",
        " \n",
        "\n",
        "\n",
        " \n",
        "numeric_features2 = ['total_sold']\n",
        "preprocessor2 = ColumnTransformer(\n",
        "transformers=[\n",
        "(\"num\", numeric_transformer, numeric_features2)\n",
        "]\n",
        ")\n",
        "\n",
        " \n",
        "\n",
        "\n",
        " \n",
        "\n",
        "enc = preprocessor.fit_transform(X_train)\n",
        "\n",
        " \n",
        "\n",
        "\n",
        " \n",
        "X_train_encoded = pd.DataFrame.sparse.from_spmatrix(enc)\n",
        "X_test_encoded = pd.DataFrame.sparse.from_spmatrix(preprocessor.transform(X_test))\n",
        "X_val_encoded = pd.DataFrame.sparse.from_spmatrix(preprocessor.transform(X_val))\n",
        "\n",
        " \n",
        "\n",
        "\n",
        " \n",
        "enc2 = preprocessor2.fit_transform(y_train)\n",
        "\n",
        " \n",
        "\n",
        "\n",
        " \n",
        "y_train_encoded = pd.DataFrame(enc2)\n",
        "y_test_encoded = pd.DataFrame(preprocessor2.transform(y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-InIdr2DKRa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMy1pmC4C4fP"
      },
      "source": [
        "from azureml.core import Run\n",
        "import argparse\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pyodbc\n",
        "#------------------------\n",
        "run = Run.get_context()\n",
        "parser=argparse.ArgumentParser('aggregation')\n",
        "parser.add_argument('--input',type=str)\n",
        "parser.add_argument('--output',type=str) \n",
        "args = parser.parse_args()\n",
        "input1=args.input  #parse the 'aggregation' data refernce for input data location\n",
        "output = args.output #parse the argument to get the file location\n",
        "input_file = input1 + \"/agg_input.csv\"\n",
        "df=pd.read_csv(input_file)\n",
        "#------------------------\n",
        "def area_allsl(df):\n",
        "    #functions takes the preprocessed df as input\n",
        "    #categorical df\n",
        "    df1=df[['DimDateKey','FYMonthsAgo','UserDefAreaHierarchy1', 'UserDefSLHierarchy1', 'UserDefSLHierarchy2','RankCDName', 'CompensationBracket', 'CumlativeBadgeCountCategory', 'PromotionsCount', 'HireCount', 'UserDefAreaHierarchy1Change', 'HiresCampus', 'HiresExperienced', 'HiresExecutive', 'HiresIntern', 'HeadCount', 'Workforce']]\n",
        "    #num df\n",
        "    df2=df[['DimDateKey','FYMonthsAgo','UserDefAreaHierarchy1', 'UserDefSLHierarchy1', 'UserDefSLHierarchy2','RankCDName', 'GPSPctFavorableUtilizationCareerOpties', 'GPSPctFavorableUtilizationWorkLifeBalance', 'GPSPctFavorableUtilizationLearningOpties','effective_utilization','LeadScorePPEDD']]\n",
        "    # # Numerical GroupBy\n",
        "    # In[30]:\n",
        "    df_grp_num=df2.drop(['UserDefSLHierarchy1','UserDefSLHierarchy2'],axis=1).groupby(['UserDefAreaHierarchy1','RankCDName','DimDateKey','FYMonthsAgo']).mean()\n",
        "    df_grp_num=df_grp_num.reset_index()\n",
        "    a=['All' for i in range(len(df_grp_num))]\n",
        "    df_grp_num['UserDefSLHierarchy1']=a\n",
        "    df_grp_num['UserDefSLHierarchy2']=a\n",
        "    #Categorical GroupBy\n",
        "    #can be use for all categorical variables to give a proportion\n",
        "    def proportion(df):\n",
        "        a=(df.value_counts()/len(df)).values\n",
        "        b=(df.value_counts()/len(df)).index\n",
        "        res = {b[i]: a[i] for i in range(len(b))}\n",
        "        return(res)\n",
        "    #should be used for binary categories in which denominator should be hirecount/headcount  \n",
        "    def proportion_denom(df):\n",
        "        a=(df[df.columns[0]].value_counts()/sum(df[df.columns[1]])).values\n",
        "        b=(df[df.columns[0]].value_counts()/sum(df[df.columns[1]])).index\n",
        "        if(len(b)>1):\n",
        "            res = {b[i]:a[i] for i in range(len(b))}\n",
        "        elif(0 in b):\n",
        "            res={0:1,1:0}\n",
        "        else:\n",
        "            res={0:0,1:1}\n",
        "        return(res)\n",
        "    grp_cmp=df1.drop(['UserDefSLHierarchy1','UserDefSLHierarchy2'],axis=1).groupby(['UserDefAreaHierarchy1','RankCDName','DimDateKey','FYMonthsAgo'])\n",
        "    cols2=['HiresCampus', 'HiresExperienced', 'HiresExecutive', 'HiresIntern']\n",
        "    combined_df=grp_cmp[['HireCount','HeadCount']].apply(proportion_denom)\n",
        "    combined_df=pd.DataFrame(combined_df).reset_index()\n",
        "    a=[]\n",
        "    b=[]\n",
        "    for i in combined_df[0]:\n",
        "        a.append(i[0])\n",
        "        b.append(i[1])\n",
        "    combined_df['HireCount_0']=a\n",
        "    combined_df['HireCount_1']=b\n",
        "    combined_df=combined_df.drop(0,axis=1)\n",
        "    for j in cols2:\n",
        "        d=grp_cmp[[j,'HireCount']].apply(proportion_denom)\n",
        "        d=pd.DataFrame(d).reset_index()\n",
        "        a=[]\n",
        "        b=[]\n",
        "        for i in d[0]:\n",
        "            a.append(i[0])\n",
        "            b.append(i[1])\n",
        "        combined_df[j+'_0']=a\n",
        "        combined_df[j+'_1']=b\n",
        "    a=['All' for i in range(len(combined_df))]\n",
        "    combined_df['UserDefSLHierarchy2']=a\n",
        "    combined_df['UserDefSLHierarchy1']=a\n",
        "#     combined_df.head()\n",
        "    cols1=['CumlativeBadgeCountCategory', 'PromotionsCount', 'UserDefAreaHierarchy1Change', 'Workforce']\n",
        "    combined_df2=grp_cmp['CompensationBracket'].apply(proportion)\n",
        "    combined_df2=pd.DataFrame(combined_df2).reset_index()\n",
        "    combined_df2['CompensationBracket_index']=combined_df2['level_4']\n",
        "    combined_df2=combined_df2.drop('level_4',axis=1)\n",
        "    for i in cols1:\n",
        "        d=grp_cmp[i].apply(proportion)\n",
        "        d=pd.DataFrame(d).reset_index()\n",
        "combined_df2[i+'_index']=d['level_4']\n",
        "        combined_df2[i]=d[i]\n",
        "#     combined_df2.head()\n",
        "    a=['All' for i in range(len(combined_df2))]\n",
        "    combined_df2['UserDefSLHierarchy2']=a\n",
        "    combined_df2['UserDefSLHierarchy1']=a\n",
        "#     combined_df2.head()\n",
        "    # combined_df.to_csv('combined_categorical.csv')\n",
        "    a=(combined_df2.pivot_table('CompensationBracket',['UserDefAreaHierarchy1', 'UserDefSLHierarchy1', \n",
        "                                                   'UserDefSLHierarchy2', 'RankCDName', 'DimDateKey','FYMonthsAgo'],'CompensationBracket_index')).reset_index()\n",
        "    cols=['CumlativeBadgeCountCategory', 'PromotionsCount',  'UserDefAreaHierarchy1Change', 'Workforce']\n",
        "    for i in cols:\n",
        "        b=(combined_df2.pivot_table(i,['UserDefAreaHierarchy1', 'UserDefSLHierarchy1', \n",
        "                                                   'UserDefSLHierarchy2', 'RankCDName', 'DimDateKey','FYMonthsAgo'],i+'_index')).reset_index()\n",
        "        l=len(combined_df2[i+'_index'].value_counts())\n",
        "        b=b[b.columns[-l:]]\n",
        "        n=[]\n",
        "        for j in b.columns:\n",
        "            n.append(str(i)+'_'+str(j))\n",
        "        b.columns=n\n",
        "        a=pd.concat([a,b],axis=1)\n",
        "#     a.head()#propotions dataframe without hirecount and headcount\n",
        "    categorical_df=pd.merge(a,combined_df,on=['UserDefAreaHierarchy1', 'UserDefSLHierarchy1', 'UserDefSLHierarchy2', 'RankCDName', 'DimDateKey', 'FYMonthsAgo'])\n",
        "#     categorical_df.head()\n",
        "    categorical_df.columns=['UserDefAreaHierarchy1', 'UserDefSLHierarchy1', 'UserDefSLHierarchy2', 'RankCDName', 'DimDateKey', 'FYMonthsAgo', 'CompensationBracket_High', 'CompensationBracket_Low', 'CompensationBracket_Medium', 'CumlativeBadgeCountCategory_Badge(s) begun but not complete', 'CumlativeBadgeCountCategory_More than one badge complete', 'CumlativeBadgeCountCategory_No badges begun', 'CumlativeBadgeCountCategory_One badge complete', 'PromotionsCount_0.0', 'PromotionsCount_1.0', 'UserDefAreaHierarchy1Change_0.0', 'UserDefAreaHierarchy1Change_1.0', 'Workforce_0.0', 'Workforce_1.0', 'HireCount_0', 'HireCount_1', 'HiresCampus_0', 'HiresCampus_1', 'HiresExperienced_0', 'HiresExperienced_1', 'HiresExecutive_0', 'HiresExecutive_1', 'HiresIntern_0', 'HiresIntern_1']\n",
        "    categorical_df=categorical_df.fillna(0)\n",
        "    categorical_df=categorical_df.drop(['HireCount_0','HiresCampus_0','HiresExperienced_0','HiresExecutive_0',\n",
        "                                        'PromotionsCount_0.0','UserDefAreaHierarchy1Change_0.0','HiresIntern_0'],axis=1)\n",
        "#     categorical_df.head()\n",
        "    # Merging columns\n",
        "    # In[47]:\n",
        "    # temp1=pd.merge(categorical_df,df_grp_num,on=['UserDefAreaHierarchy1', 'UserDefSLHierarchy1', 'UserDefSLHierarchy2','RankCDName'])\n",
        "    # temp1.head()\n",
        "    temp2=pd.merge(categorical_df,df_grp_num,on=['UserDefAreaHierarchy1', 'UserDefSLHierarchy1', 'UserDefSLHierarchy2','RankCDName','DimDateKey','FYMonthsAgo'])\n",
        "#     temp2.head()\n",
        "    temp2.columns=['ManagerialArea','ServiceLine','SubServiceLine','Rank','DimDateKey', 'FYMonthsAgo', '% in High Compensation Bracket', '% in Low Compensation Bracket', '% in Medium Compensation Bracket', '% Began Badge Journey', '% Completed More Than One Badge', '% Not Began Badge Journey', '% Completed Exactly One Badge ', '% Promoted in Last Year', '% Switched Service Lines', '% Not as Headcount (e.g. Contract)', '% Headcount (e.g. FTE)', '% New Hires among Employees', '% Campus Hires among New Hires', '% Experienced Hires among New Hires', '% Executive Hires among New Hires', '% Interns among New Hires', 'GPS: % Favorable of Career Opportunities', 'GPS: % Favorable of Work/Life Balance', 'GPS: % Favorable of Learning Opportunities', 'effective_utilization','Average PPEDDs LEAD Score']\n",
        "    #  temp2.head()\n",
        "    # temp2.to_csv('Area-All SL.csv')\n",
        "    return(temp2)\n",
        "df1,df2,df3,df4,df5,df6=area_allsl(df),area_sl_allsll(df),area_sl_ssl(df),allarea_allsl(df),allarea_sl_allsll(df),allarea_sl_ssl(df)\n",
        "combdf=pd.concat([df1,df2,df3,df4,df5,df6],axis=0)\n",
        "# combdf.head()\n",
        "df_final=combdf[['ManagerialArea','ServiceLine','SubServiceLine','Rank','DimDateKey', 'FYMonthsAgo', '% in High Compensation Bracket', '% in Low Compensation Bracket', '% in Medium Compensation Bracket', '% Began Badge Journey', '% Completed More Than One Badge', '% Not Began Badge Journey', '% Completed Exactly One Badge ', '% Promoted in Last Year', '% Switched Service Lines', '% Not as Headcount (e.g. Contract)', '% Headcount (e.g. FTE)', '% New Hires among Employees', '% Campus Hires among New Hires', '% Experienced Hires among New Hires', '% Executive Hires among New Hires', '% Interns among New Hires', 'GPS: % Favorable of Career Opportunities', 'GPS: % Favorable of Work/Life Balance', 'GPS: % Favorable of Learning Opportunities', 'effective_utilization','Average PPEDDs LEAD Score']]\n",
        "a=np.arange(0,len(df_final))\n",
        "df_final.index=a\n",
        "# df_final.head()\n",
        "# making directory and writing to csv which is later used for modelling\n",
        "os.makedirs(output, exist_ok=True)\n",
        "output_path = output + \"/model_input.csv\"\n",
        "print(output_path)\n",
        "df_final.to_csv(output_path)\n",
        "print(df_final.head())\n",
        "run.complete()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "458u8FZRDO3h"
      },
      "source": [
        "from azureml.pipeline.core import PipelineData,Pipeline\n",
        "from azureml.pipeline.steps import PythonScriptStep\n",
        "agg_input=PipelineData('agg_input',datastore=def_blob_store).as_dataset()\n",
        "model_input=PipelineData('model_input',datastore=def_blob_store).as_dataset()\n",
        "from azureml.pipeline.steps import PythonScriptStep\n",
        "source_directory =cwd\n",
        "#2-mlcomputeD12\n",
        "#-mlwrkspaceSP02\n",
        "# built-in step to run a Python Script on a compute target. It takes a script name and optionally other parameters like arguments for the script, compute target, inputs and outputs.\n",
        "dataread = PythonScriptStep(\n",
        "    name=\"Data_read\",\n",
        "    script_name=\"DataRead.py\", \n",
        "    arguments=['--output',agg_input],\n",
        "    outputs=[agg_input],\n",
        "    source_directory=source_directory,\n",
        "    compute_target=data_read_compute,\n",
        "    runconfig=run_config)\n",
        "agg=PythonScriptStep(name='aggregation',\n",
        "                      script_name='aggregation.py',\n",
        "                      arguments=['--input',agg_input,'--output',model_input],\n",
        "                      inputs=[agg_input],\n",
        "                      outputs=[model_input],\n",
        "                      compute_target=data_read_compute,\n",
        "                      runconfig=run_config,\n",
        "                      source_directory=source_directory,\n",
        "                      allow_reuse=True)\n",
        "model=PythonScriptStep(name='modelling',\n",
        "                      script_name='modelling.py',\n",
        "                      arguments=['--input',model_input],\n",
        "                      inputs=[model_input],\n",
        "#                       outputs=[model_input],\n",
        "                      compute_target=aml_compute,\n",
        "                      runconfig=run_config,\n",
        "                      source_directory=source_directory,\n",
        "                      allow_reuse=True)\n",
        "pipeline=Pipeline(workspace=ws,steps=[dataread,agg,model])\n",
        "pipeline.validate() #validating pipelines for circular dependencies and parameter checks etc.\n",
        "from azureml.core import Experiment\n",
        "# create an ML experiment\n",
        "exp = Experiment(workspace=ws, name='60ML')\n",
        "from datetime import datetime\n",
        "from azureml.pipeline.core.schedule import ScheduleRecurrence, Schedule,TimeZone\n",
        "timenow = datetime.now().strftime('%m-%d-%Y-%H-%M')\n",
        "pipeline_name = timenow + \"-Pipeline\"\n",
        "print(pipeline_name)\n",
        "published_pipeline1 = pipeline.publish(\n",
        "name=pipeline_name,\n",
        "description=pipeline_name)\n",
        "print(\"Newly published pipeline id: {} \".format(published_pipeline1.id))\n",
        "pub_pipeline_id=published_pipeline1.id\n",
        "import datetime\n",
        "start_time = datetime.datetime(year=2020, month=10, day=12, hour=16,minute=18,second=0)\n",
        "recurrence = ScheduleRecurrence(frequency=\"Hour\", interval=3,start_time=start_time,time_zone=TimeZone.IndiaStandardTime)\n",
        "schedule = Schedule.create(workspace=ws, name=\"PX360_schedule\",pipeline_id=pub_pipeline_id,experiment_name='PX360_schedule_exp',\n",
        "                        recurrence=recurrence,\n",
        "                        wait_for_provisioning=True,\n",
        "                        description=\"Schedule Run\")\n",
        "# You may want to make sure that the schedule is provisioned properly\n",
        "# before making any further changes to the schedule\n",
        "print(\"Created schedule with id: {} \".format(schedule.id))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eGMoviENt2D"
      },
      "source": [
        "from azureml.pipeline.core import PipelineData,Pipeline\n",
        "from azureml.pipeline.steps import PythonScriptStep\n",
        "agg_input=PipelineData('agg_input',datastore=def_blob_store).as_dataset()\n",
        "model_input=PipelineData('model_input',datastore=def_blob_store).as_dataset()\n",
        "from azureml.pipeline.steps import PythonScriptStep\n",
        "source_directory =cwd\n",
        "#2-mlcomputeD12\n",
        "#-mlwrkspaceSP02\n",
        "# built-in step to run a Python Script on a compute target. It takes a script name and optionally other parameters like arguments for the script, compute target, inputs and outputs.\n",
        "dataread = PythonScriptStep(\n",
        "    name=\"Data_read\",\n",
        "    script_name=\"DataRead.py\", \n",
        "    arguments=['--output',agg_input],\n",
        "    outputs=[agg_input],\n",
        "    source_directory=source_directory,\n",
        "    compute_target=data_read_compute,\n",
        "    runconfig=run_config)\n",
        "agg=PythonScriptStep(name='aggregation',\n",
        "                      script_name='aggregation.py',\n",
        "                      arguments=['--input',agg_input,'--output',model_input],\n",
        "                      inputs=[agg_input],\n",
        "                      outputs=[model_input],\n",
        "                      compute_target=data_read_compute,\n",
        "                      runconfig=run_config,\n",
        "                      source_directory=source_directory,\n",
        "                      allow_reuse=True)\n",
        "model=PythonScriptStep(name='modelling',\n",
        "                      script_name='modelling.py',\n",
        "                      arguments=['--input',model_input],\n",
        "                      inputs=[model_input],\n",
        "#                       outputs=[model_input],\n",
        "                      compute_target=aml_compute,\n",
        "                      runconfig=run_config,\n",
        "                      source_directory=source_directory,\n",
        "                      allow_reuse=True)\n",
        "pipeline=Pipeline(workspace=ws,steps=[dataread,agg,model])\n",
        "pipeline.validate() #validating pipelines for circular dependencies and parameter checks etc.\n",
        "from azureml.core import Experiment\n",
        "# create an ML experiment\n",
        "exp = Experiment(workspace=ws, name='60ML')\n",
        "from datetime import datetime\n",
        "from azureml.pipeline.core.schedule import ScheduleRecurrence, Schedule,TimeZone\n",
        "timenow = datetime.now().strftime('%m-%d-%Y-%H-%M')\n",
        "pipeline_name = timenow + \"-Pipeline\"\n",
        "print(pipeline_name)\n",
        "published_pipeline1 = pipeline.publish(\n",
        "name=pipeline_name,\n",
        "description=pipeline_name)\n",
        "print(\"Newly published pipeline id: {} \".format(published_pipeline1.id))\n",
        "pub_pipeline_id=published_pipeline1.id\n",
        "import datetime\n",
        "start_time = datetime.datetime(year=2020, month=10, day=12, hour=16,minute=18,second=0)\n",
        "recurrence = ScheduleRecurrence(frequency=\"Hour\", interval=3,start_time=start_time,time_zone=TimeZone.IndiaStandardTime)\n",
        "schedule = Schedule.create(workspace=ws, name=\"PX360_schedule\",pipeline_id=pub_pipeline_id,experiment_name='PX360_schedule_exp',\n",
        "                        recurrence=recurrence,\n",
        "                        wait_for_provisioning=True,\n",
        "                        description=\"Schedule Run\")\n",
        "# You may want to make sure that the schedule is provisioned properly\n",
        "# before making any further changes to the schedule\n",
        "print(\"Created schedule with id: {} \".format(schedule.id))\n",
        "#data agg\n",
        "from azureml.core import Run\n",
        "import argparse\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pyodbc\n",
        "#------------------------\n",
        "run = Run.get_context()\n",
        "parser=argparse.ArgumentParser('aggregation')\n",
        "parser.add_argument('--input',type=str)\n",
        "parser.add_argument('--output',type=str) \n",
        "args = parser.parse_args()\n",
        "input1=args.input  #parse the 'aggregation' data refernce for input data location\n",
        "output = args.output #parse the argument to get the file location\n",
        "input_file = input1 + \"/agg_input.csv\"\n",
        "df=pd.read_csv(input_file)\n",
        "#------------------------\n",
        "def area_allsl(df):\n",
        "    #functions takes the preprocessed df as input\n",
        "    #categorical df\n",
        "    df1=df[['DimDateKey','FYMonthsAgo','UserDefAreaHierarchy1', 'UserDefSLHierarchy1', 'UserDefSLHierarchy2','RankCDName', 'CompensationBracket', 'CumlativeBadgeCountCategory', 'PromotionsCount', 'HireCount', 'UserDefAreaHierarchy1Change', 'HiresCampus', 'HiresExperienced', 'HiresExecutive', 'HiresIntern', 'HeadCount', 'Workforce']]\n",
        "    #num df\n",
        "    df2=df[['DimDateKey','FYMonthsAgo','UserDefAreaHierarchy1', 'UserDefSLHierarchy1', 'UserDefSLHierarchy2','RankCDName', 'GPSPctFavorableUtilizationCareerOpties', 'GPSPctFavorableUtilizationWorkLifeBalance', 'GPSPctFavorableUtilizationLearningOpties','effective_utilization','LeadScorePPEDD']]\n",
        "    # # Numerical GroupBy\n",
        "    # In[30]:\n",
        "    df_grp_num=df2.drop(['UserDefSLHierarchy1','UserDefSLHierarchy2'],axis=1).groupby(['UserDefAreaHierarchy1','RankCDName','DimDateKey','FYMonthsAgo']).mean()\n",
        "    df_grp_num=df_grp_num.reset_index()\n",
        "    a=['All' for i in range(len(df_grp_num))]\n",
        "    df_grp_num['UserDefSLHierarchy1']=a\n",
        "    df_grp_num['UserDefSLHierarchy2']=a\n",
        "    #Categorical GroupBy\n",
        "    #can be use for all categorical variables to give a proportion\n",
        "    def proportion(df):\n",
        "        a=(df.value_counts()/len(df)).values\n",
        "        b=(df.value_counts()/len(df)).index\n",
        "        res = {b[i]: a[i] for i in range(len(b))}\n",
        "        return(res)\n",
        "    #should be used for binary categories in which denominator should be hirecount/headcount  \n",
        "    def proportion_denom(df):\n",
        "        a=(df[df.columns[0]].value_counts()/sum(df[df.columns[1]])).values\n",
        "        b=(df[df.columns[0]].value_counts()/sum(df[df.columns[1]])).index\n",
        "        if(len(b)>1):\n",
        "            res = {b[i]:a[i] for i in range(len(b))}\n",
        "        elif(0 in b):\n",
        "            res={0:1,1:0}\n",
        "        else:\n",
        "            res={0:0,1:1}\n",
        "        return(res)\n",
        "    grp_cmp=df1.drop(['UserDefSLHierarchy1','UserDefSLHierarchy2'],axis=1).groupby(['UserDefAreaHierarchy1','RankCDName','DimDateKey','FYMonthsAgo'])\n",
        "    cols2=['HiresCampus', 'HiresExperienced', 'HiresExecutive', 'HiresIntern']\n",
        "    combined_df=grp_cmp[['HireCount','HeadCount']].apply(proportion_denom)\n",
        "    combined_df=pd.DataFrame(combined_df).reset_index()\n",
        "    a=[]\n",
        "    b=[]\n",
        "    for i in combined_df[0]:\n",
        "        a.append(i[0])\n",
        "        b.append(i[1])\n",
        "    combined_df['HireCount_0']=a\n",
        "    combined_df['HireCount_1']=b\n",
        "    combined_df=combined_df.drop(0,axis=1)\n",
        "    for j in cols2:\n",
        "        d=grp_cmp[[j,'HireCount']].apply(proportion_denom)\n",
        "        d=pd.DataFrame(d).reset_index()\n",
        "        a=[]\n",
        "        b=[]\n",
        "        for i in d[0]:\n",
        "            a.append(i[0])\n",
        "            b.append(i[1])\n",
        "        combined_df[j+'_0']=a\n",
        "        combined_df[j+'_1']=b\n",
        "    a=['All' for i in range(len(combined_df))]\n",
        "    combined_df['UserDefSLHierarchy2']=a\n",
        "    combined_df['UserDefSLHierarchy1']=a\n",
        "#     combined_df.head()\n",
        "    cols1=['CumlativeBadgeCountCategory', 'PromotionsCount', 'UserDefAreaHierarchy1Change', 'Workforce']\n",
        "    combined_df2=grp_cmp['CompensationBracket'].apply(proportion)\n",
        "    combined_df2=pd.DataFrame(combined_df2).reset_index()\n",
        "    combined_df2['CompensationBracket_index']=combined_df2['level_4']\n",
        "    combined_df2=combined_df2.drop('level_4',axis=1)\n",
        "    for i in cols1:\n",
        "        d=grp_cmp[i].apply(proportion)\n",
        "        d=pd.DataFrame(d).reset_index()\n",
        "combined_df2[i+'_index']=d['level_4']\n",
        "        combined_df2[i]=d[i]\n",
        "#     combined_df2.head()\n",
        "    a=['All' for i in range(len(combined_df2))]\n",
        "    combined_df2['UserDefSLHierarchy2']=a\n",
        "    combined_df2['UserDefSLHierarchy1']=a\n",
        "#     combined_df2.head()\n",
        "    # combined_df.to_csv('combined_categorical.csv')\n",
        "    a=(combined_df2.pivot_table('CompensationBracket',['UserDefAreaHierarchy1', 'UserDefSLHierarchy1', \n",
        "                                                   'UserDefSLHierarchy2', 'RankCDName', 'DimDateKey','FYMonthsAgo'],'CompensationBracket_index')).reset_index()\n",
        "    cols=['CumlativeBadgeCountCategory', 'PromotionsCount',  'UserDefAreaHierarchy1Change', 'Workforce']\n",
        "    for i in cols:\n",
        "        b=(combined_df2.pivot_table(i,['UserDefAreaHierarchy1', 'UserDefSLHierarchy1', \n",
        "                                                   'UserDefSLHierarchy2', 'RankCDName', 'DimDateKey','FYMonthsAgo'],i+'_index')).reset_index()\n",
        "        l=len(combined_df2[i+'_index'].value_counts())\n",
        "        b=b[b.columns[-l:]]\n",
        "        n=[]\n",
        "        for j in b.columns:\n",
        "            n.append(str(i)+'_'+str(j))\n",
        "        b.columns=n\n",
        "        a=pd.concat([a,b],axis=1)\n",
        "#     a.head()#propotions dataframe without hirecount and headcount\n",
        "    categorical_df=pd.merge(a,combined_df,on=['UserDefAreaHierarchy1', 'UserDefSLHierarchy1', 'UserDefSLHierarchy2', 'RankCDName', 'DimDateKey', 'FYMonthsAgo'])\n",
        "#     categorical_df.head()\n",
        "    categorical_df.columns=['UserDefAreaHierarchy1', 'UserDefSLHierarchy1', 'UserDefSLHierarchy2', 'RankCDName', 'DimDateKey', 'FYMonthsAgo', 'CompensationBracket_High', 'CompensationBracket_Low', 'CompensationBracket_Medium', 'CumlativeBadgeCountCategory_Badge(s) begun but not complete', 'CumlativeBadgeCountCategory_More than one badge complete', 'CumlativeBadgeCountCategory_No badges begun', 'CumlativeBadgeCountCategory_One badge complete', 'PromotionsCount_0.0', 'PromotionsCount_1.0', 'UserDefAreaHierarchy1Change_0.0', 'UserDefAreaHierarchy1Change_1.0', 'Workforce_0.0', 'Workforce_1.0', 'HireCount_0', 'HireCount_1', 'HiresCampus_0', 'HiresCampus_1', 'HiresExperienced_0', 'HiresExperienced_1', 'HiresExecutive_0', 'HiresExecutive_1', 'HiresIntern_0', 'HiresIntern_1']\n",
        "    categorical_df=categorical_df.fillna(0)\n",
        "    categorical_df=categorical_df.drop(['HireCount_0','HiresCampus_0','HiresExperienced_0','HiresExecutive_0',\n",
        "                                        'PromotionsCount_0.0','UserDefAreaHierarchy1Change_0.0','HiresIntern_0'],axis=1)\n",
        "#     categorical_df.head()\n",
        "    # Merging columns\n",
        "    # In[47]:\n",
        "    # temp1=pd.merge(categorical_df,df_grp_num,on=['UserDefAreaHierarchy1', 'UserDefSLHierarchy1', 'UserDefSLHierarchy2','RankCDName'])\n",
        "    # temp1.head()\n",
        "    temp2=pd.merge(categorical_df,df_grp_num,on=['UserDefAreaHierarchy1', 'UserDefSLHierarchy1', 'UserDefSLHierarchy2','RankCDName','DimDateKey','FYMonthsAgo'])\n",
        "#     temp2.head()\n",
        "    temp2.columns=['ManagerialArea','ServiceLine','SubServiceLine','Rank','DimDateKey', 'FYMonthsAgo', '% in High Compensation Bracket', '% in Low Compensation Bracket', '% in Medium Compensation Bracket', '% Began Badge Journey', '% Completed More Than One Badge', '% Not Began Badge Journey', '% Completed Exactly One Badge ', '% Promoted in Last Year', '% Switched Service Lines', '% Not as Headcount (e.g. Contract)', '% Headcount (e.g. FTE)', '% New Hires among Employees', '% Campus Hires among New Hires', '% Experienced Hires among New Hires', '% Executive Hires among New Hires', '% Interns among New Hires', 'GPS: % Favorable of Career Opportunities', 'GPS: % Favorable of Work/Life Balance', 'GPS: % Favorable of Learning Opportunities', 'effective_utilization','Average PPEDDs LEAD Score']\n",
        "    #  temp2.head()\n",
        "    # temp2.to_csv('Area-All SL.csv')\n",
        "    return(temp2)\n",
        "df1,df2,df3,df4,df5,df6=area_allsl(df),area_sl_allsll(df),area_sl_ssl(df),allarea_allsl(df),allarea_sl_allsll(df),allarea_sl_ssl(df)\n",
        "combdf=pd.concat([df1,df2,df3,df4,df5,df6],axis=0)\n",
        "# combdf.head()\n",
        "df_final=combdf[['ManagerialArea','ServiceLine','SubServiceLine','Rank','DimDateKey', 'FYMonthsAgo', '% in High Compensation Bracket', '% in Low Compensation Bracket', '% in Medium Compensation Bracket', '% Began Badge Journey', '% Completed More Than One Badge', '% Not Began Badge Journey', '% Completed Exactly One Badge ', '% Promoted in Last Year', '% Switched Service Lines', '% Not as Headcount (e.g. Contract)', '% Headcount (e.g. FTE)', '% New Hires among Employees', '% Campus Hires among New Hires', '% Experienced Hires among New Hires', '% Executive Hires among New Hires', '% Interns among New Hires', 'GPS: % Favorable of Career Opportunities', 'GPS: % Favorable of Work/Life Balance', 'GPS: % Favorable of Learning Opportunities', 'effective_utilization','Average PPEDDs LEAD Score']]\n",
        "a=np.arange(0,len(df_final))\n",
        "df_final.index=a\n",
        "# df_final.head()\n",
        "# making directory and writing to csv which is later used for modelling\n",
        "os.makedirs(output, exist_ok=True)\n",
        "output_path = output + \"/model_input.csv\"\n",
        "print(output_path)\n",
        "df_final.to_csv(output_path)\n",
        "print(df_final.head())\n",
        "run.complete()\n",
        "#dta read\n",
        "from azureml.core import Run\n",
        "import argparse\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pyodbc\n",
        "# dataset object from the run\n",
        "parser=argparse.ArgumentParser('Data_read')\n",
        "parser.add_argument('--output',type=str)\n",
        "args = parser.parse_args()\n",
        "output = args.output\n",
        "df.head()\n",
        " Save the dataframe\n",
        "os.makedirs(output, exist_ok=True)\n",
        "output_path = output + \"/agg_input.csv\"\n",
        "print(output_path)\n",
        "df.to_csv(output_path)\n",
        "\n",
        "\n",
        "Adarsh\n",
        "j\n",
        "\n",
        "Adarsh\n",
        "px modelling\n",
        "from azureml.core import Run\n",
        "import argparse\n",
        "import os\n",
        "import pandas as pd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression,Ridge,Lasso,ElasticNet\n",
        "from sklearn.model_selection import train_test_split,KFold,GridSearchCV\n",
        "from sklearn import metrics\n",
        "from sklearn import model_selection\n",
        "from sklearn.impute import KNNImputer\n",
        "import pyodbc\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import KNNImputer\n",
        "from scipy.stats import pearsonr\n",
        "from datetime import date\n",
        "# dataset object from the run\n",
        "run = Run.get_context()\n",
        "parser=argparse.ArgumentParser('aggregation')\n",
        "parser.add_argument('--input',type=str)\n",
        "# parser.add_argument('--output',type=str)\n",
        "\n",
        "args = parser.parse_args()\n",
        "input1=args.input\n",
        "# output = args.output\n",
        "pd.set_option('display.max_rows', 500)\n",
        "input_file = input1 + \"/model_input.csv\"\n",
        "df_fact=pd.read_csv(input_file,index_col=0)\n",
        "cxn=\n",
        "df_metric=pd.read_sql('SELECT  * FROM EY_PX360_PRD.MetricInformation',cnxn)\n",
        "df_metric=df_metric.drop(['UpdatedDateTime'],axis=1)\n",
        "df_metric['Rank']=df_metric['RankCDName']\n",
        "df_metric=df_metric.drop('RankCDName',axis=1)\n",
        "df_metric=df_metric.replace('$null$',np.nan)\n",
        "\n",
        "df_metric['MetricValue']=df_metric['MetricValue'].astype(float)\n",
        "\n",
        "df_metric=df_metric.drop(['ManagerialRegion','Country','UnitOfMetric','FrontEndReady','Headcount'],axis=1)\n",
        "df_metric_pivot=(df_metric.pivot_table('MetricValue',['FYMonthsAgo', 'ServiceLine', 'SubServiceLine', 'ManagerialArea', \n",
        "                                         'Rank'],'MetricName')).reset_index()\n",
        "\n",
        "metrics=df_metric['MetricName'].unique()\n",
        "def automate(area,sl,subsl,Target):\n",
        "    \n",
        "    #filtering\n",
        "    global df_fact\n",
        "    df_fact=df_fact[(df_fact['Rank']!='55-Administrative Lead')&(df_fact['Rank']!='56-Administrative Advanced')&\n",
        "        (df_fact['Rank']!='57-Administrative Intermediate')&(df_fact['Rank']!='58-Administrative Entry')]\n",
        "    df_filter_fact=df_fact[(df_fact['ManagerialArea']==area)&(df_fact['ServiceLine']==sl)\n",
        "                      &(df_fact['SubServiceLine']==subsl)]\n",
        "    df_filter_metric=df_metric_pivot[(df_metric_pivot['ManagerialArea']==area)&(df_metric_pivot['ServiceLine']==sl)\n",
        "                                &(df_metric_pivot['SubServiceLine']==subsl)]\n",
        "    #merging\n",
        "    cols=['% in High Compensation Bracket', '% in Low Compensation Bracket', '% in Medium Compensation Bracket', \n",
        "          '% Began Badge Journey', '% Completed More Than One Badge', \n",
        "          '% Not Began Badge Journey', '% Completed Exactly One Badge ', '% Promoted in Last Year', \n",
        "          '% Switched Service Lines', '% Not as Headcount (e.g. Contract)', '% Headcount (e.g. FTE)', '% New Hires among Employees', '% Campus Hires among New Hires', '% Experienced Hires among New Hires', '% Executive Hires among New Hires', '% Interns among New Hires']\n",
        "    for i in cols:\n",
        "        df_filter_fact[i]=df_filter_fact[i].fillna(0)\n",
        "    temp1=pd.merge(df_filter_fact,df_filter_metric,on=['ManagerialArea', 'FYMonthsAgo', 'ServiceLine', 'SubServiceLine','Rank'],how='inner')\n",
        "    #preprocessing\n",
        "    rej_logs=\"\"\n",
        "    temp1=temp1.drop('effective_utilization',axis=1)\n",
        "    init_shape=temp1.shape[1]\n",
        "    temp1=temp1[temp1[Target].isna()==False]\n",
        "    temp1=temp1[temp1.columns[(temp1.isnull().sum()<(0.6*len(temp1))).values]]\n",
        "    cur_shape=temp1.shape[1]\n",
        "    if(init_shape>cur_shape):\n",
        "        rej_logs_null=\"Discarded Columns having more than 60% null values\"\n",
        "    else:\n",
        "        rej_logs_null=\"\"\n",
        "    if(len(temp1)>0):\n",
        "        temp1=temp1.drop_duplicates()\n",
        "    if(len(temp1)>10):        \n",
        "        #splitting Data\n",
        "        X=temp1.drop(['ManagerialArea','ServiceLine','SubServiceLine',Target,'DimDateKey','FYMonthsAgo'],axis=1)\n",
        "        y=temp1[Target]\n",
        "        if(Target=='Eff. Utilization'):\n",
        "            X=X[(X['Rank']=='44-Staff/Assistant')|(X['Rank']=='42-Senior')\n",
        "               |(X['Rank']=='32-Manager')|(X['Rank']=='21-Senior Manager')|(X['Rank']=='11-Partner/Principal')|\n",
        "               (X['Rank']=='13-Executive Director')]\n",
        "        X['Rank']=X['Rank'].map({'44-Staff/Assistant':1,'42-Senior':2,'32-Manager':3,'21-Senior Manager':4,'11-Partner/Principal':6,\n",
        "                          '13-Executive Director':5,'51-Intern (CS)':0,'53-Intern (CBS)':0,'05-Non Emp CBS':0,'04-Non Emp CS':0,\n",
        "                                    '66-Associate':1,'65-Senior Associate':2,'64-Supv Associate':3,'63-Assistant Director':4\n",
        "                                    ,'62-Associate Director':5,'61-Director':6})\n",
        "        #scaling the data\n",
        "        sc=StandardScaler()\n",
        "        for i in X.columns:\n",
        "            X[i]=sc.fit_transform(X[[i]])\n",
        "        #knn imputation\n",
        "        imputer=KNNImputer()\n",
        "        imputer.fit(X)\n",
        "        X_KNN=imputer.transform(X)\n",
        "        X_knn=pd.DataFrame(X_KNN)\n",
        "        X_knn.columns=X.columns\n",
        "        ridge_model=Ridge(normalize=True)\n",
        "        #feature selection using pearsonr correlation test\n",
        "        X_corr=X_knn.copy()\n",
        "        r_val,pval,col=[],[],[]\n",
        "        for i in X_corr.columns:\n",
        "            r, p = pearsonr(X_corr[i], y)\n",
        "            r_val.append(r)\n",
        "            pval.append(p)\n",
        "        crdf=pd.DataFrame(columns=[\"Coeff\",\"pvalue\",\"feature\"])\n",
        "        crdf[\"Coeff\"]=r_val\n",
        "        crdf[\"pvalue\"]=pval\n",
        "        crdf[\"feature\"]=list(X_corr.columns)\n",
        "        features_pearson=list(crdf[crdf[\"pvalue\"]<0.05]['feature'])\n",
        "        X_knn=X_knn[features_pearson]\n",
        "        #putting a cut off of features having a high  correlation among themselves\n",
        "        b=pd.DataFrame(np.tril(X_knn.corr(), k=-1))\n",
        "b.columns=X_knn.columns\n",
        "        b.index=X_knn.columns\n",
        "        X_knn=X_knn[b.index[(b[b>0.9]).any(axis=1)==False]]\n",
        "        #modelling\n",
        "        if(len(X_knn.columns)>2):\n",
        "            print(Target)\n",
        "            print('combination:',area,'-',sl,'-',subsl)   \n",
        "            valid_comb.append((area,sl,subsl))\n",
        "            global num_models\n",
        "            num_models=num_models+1\n",
        "            from sklearn.model_selection import GridSearchCV\n",
        "            params_ridge={'alpha':np.arange(0.01,1,0.01)}\n",
        "            GS_m2=GridSearchCV(ridge_model,params_ridge,cv=3,scoring='r2')\n",
        "            GS_m2.fit(X_knn,y)\n",
        "            parameter=GS_m2.best_params_['alpha']\n",
        "            ridge_model=Ridge(alpha=parameter,normalize=True)\n",
        "            models=[]\n",
        "            models.append(('Ridge',ridge_model))\n",
        "            xtrain,xtest,ytrain,ytest=train_test_split(X_knn,y,test_size=0.3,random_state=0)\n",
        "            results=[]\n",
        "            names=[]\n",
        "            for name,model in models:\n",
        "                kfold=model_selection.KFold(n_splits=3,shuffle=True,random_state=0)\n",
        "                cv_result=model_selection.cross_val_score(model,X_knn,y,cv=kfold,scoring='neg_mean_squared_error')\n",
        "                cv_result_acc=model_selection.cross_val_score(model,X_knn,y,cv=kfold,scoring='r2')\n",
        "                results.append(np.sqrt(np.abs(cv_result)))\n",
        "                names.append(name)\n",
        "                BE=np.mean(np.sqrt(np.abs(cv_result)))\n",
        "                VE=np.var(np.sqrt(np.abs(cv_result)))\n",
        "                print(name)\n",
        "                model.fit(xtrain,ytrain)\n",
        "                crossval=np.mean(cv_result_acc)\n",
        "                Training_acc=model.score(xtrain,ytrain)\n",
        "                Testing_acc=model.score(xtest,ytest)\n",
        "                print(\"\\t\\tCrossValAccuracy: \",crossval)\n",
        "                print('\\t\\tTraining Accuracy: ',Training_acc)\n",
        "                print('\\t\\tTesting ACcuracy: ',Testing_acc)\n",
        "                print('\\t\\tBias Error: ',BE)\n",
        "                print('\\t\\tVariance Error: ',VE)\n",
        "                ypred=model.predict(xtrain)\n",
        "                mse=((ypred-ytrain)**2).mean()\n",
        "                rmse=mse**0.5\n",
        "                \n",
        "                return (name,model,xtrain,ytrain,crossval,Training_acc,Testing_acc,BE,VE,rmse,len(X_knn))\n",
        "        else:\n",
        "            rej_logs=\"Failed Statistical & Peason tests\" + \" \" +rej_logs_null\n",
        "            rejected_comb.append((area,sl,subsl,rej_logs))\n",
        "            return (0,0,0,0,0,0,0,0,0,0,0)\n",
        "    else:\n",
        "#         print('No Data Exist')\n",
        "        rej_logs=\"Insufficient/Inappropriate Data for Modelling\"\n",
        "        rejected_comb.append((area,sl,subsl,rej_logs))\n",
        "        return (0,0,0,0,0,0,0,0,0,0,0)\n",
        "for metric in metrics:\n",
        "    ar=df_fact['ManagerialArea'].unique()\n",
        "    S=df_fact['ServiceLine'].unique()\n",
        "    SS=df_fact['SubServiceLine'].unique()\n",
        "    flag=False\n",
        "    valid_comb=[]\n",
        "    rejected_comb=[]\n",
        "    num_models=0\n",
        "    for i in ar:\n",
        "        for j in S:\n",
        "            for k in SS:\n",
        "                Name,Model,xtrain,ytrain,crossval,Training_acc,Testing_acc,BE,VE,rmse,length=automate(i,j,k,metric)\n",
        "                if(Name!=0 and flag==False):\n",
        "                    a=[i for p in range(len(xtrain.columns))]\n",
        "                    Model.fit(xtrain,ytrain)\n",
        "                    model_coef=pd.DataFrame({'Features':xtrain.columns,'Coefficients':Model.coef_,'Area':a,'ServiceLine':b,\n",
        "                                             'SubServiceLine':c,'Cross Validation Accuracy':d,'Training accuracy':e,\n",
        "                                             'Testing Accuracy':f,'Bias Error':g,'Variance Error':h,'RMSE':z,\n",
        "                                             'Number of Data points':y})\n",
        "                    flag=True\n",
        "    f(len(valid_comb)>0):\n",
        "        valid_comb=pd.DataFrame(valid_comb,columns=['Area','ServiceLine','SubServiceLine'])\n",
        "        valid_comb.to_csv(\"valid combinations \"+metric+\".csv\")\n",
        "        num=[num_models for p in range(len(model_coef))]\n",
        "        model_coef['Number of Models']=num\n",
        "        model_coef.to_csv(metric+'.csv')\n",
        "#write\n",
        "cols=df.columns\n",
        "df['DimDateKey']=DimDateKey\n",
        "cols=cols.insert(0,'DimDateKey')\n",
        "df=df[np.array(cols)]\n",
        "df.columns=['DimDateKey', 'Features_Number', 'Features', 'Coefficients', 'Area',\n",
        "       'ServiceLine', 'SubServiceLine', 'Cross_Validation_Accuracy',\n",
        "       'Training_accuracy', 'Testing_Accuracy', 'Bias_Error', 'Variance_Error',\n",
        "       'RMSE', 'Number_of_Data_Points', 'Number_of_Models', 'Metric']\n",
        "cursor = cnxn.cursor()\n",
        "# Insert Dataframe into SQL Server:\n",
        "for index, row in df.iterrows():\n",
        "    cursor.execute(\"\"\"INSERT INTO EY_PX360_PRD.ML_Output (DimDateKey, Features_Number, Features, Coefficients, Area,\n",
        "       ServiceLine, SubServiceLine, Cross_Validation_Accuracy,\n",
        "       Training_accuracy, Testing_Accuracy, Bias_Error, Variance_Error,\n",
        "       RMSE, Number_of_Data_Points, Number_of_Models, Metric) values(?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)\"\"\", row.DimDateKey,\n",
        "                   row.Features_Number, row.Features, row.Coefficients,row.Area,row.ServiceLine,row.SubServiceLine,\n",
        "                   row.Cross_Validation_Accuracy,row.Training_accuracy,row.Testing_Accuracy,row.Bias_Error,\n",
        "                   row.Variance_Error,row.RMSE,row.Number_of_Data_Points,row.Number_of_Models,row.Metric)\n",
        "cnxn.commit()\n",
        "cursor.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#!/usr/bin/env python\n",
        "# coding: utf-8\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression,Ridge,Lasso,ElasticNet\n",
        "from sklearn.model_selection import train_test_split,KFold,GridSearchCV\n",
        "from sklearn import metrics\n",
        "from sklearn import model_selection\n",
        "from scipy.stats import pearsonr\n",
        "import sys\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")\n",
        "from pandas_profiling import ProfileReport\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "df.head()\n",
        "mapd.head()\n",
        "mapd=mapd[['Employee Engagement.1', 'Employee Engagement.2', 'Employee Engagement.3', 'Employee Engagement.4', 'Employee Engagement.5', 'Ethics.1', 'Ethics.2', 'Ethics.3', 'Ethics.4', 'Career Development.1', 'Career Development.2', 'Supervisor/Employee Interaction.1', 'Supervisor/Employee Interaction.2', 'Supervisor/Employee Interaction.3', 'Employee Empowerment Index.1', 'Employee Empowerment Index.2', 'Employee Empowerment Index.3', 'Employee Empowerment Index.4', 'Employee Empowerment Index.5', 'Diversity and Inclusion.1', 'Diversity and Inclusion.2', 'Diversity and Inclusion.3', 'Diversity and Inclusion.4', 'Culture.1', 'Culture.2', 'Culture.3']]\n",
        "mapd\n",
        "df.head(2)\n",
        "#mapping dict\n",
        "namedict={}\n",
        "for i in df.columns:\n",
        "    if i in list(mapd.iloc[0]):\n",
        "        coname=((mapd == i).idxmax(axis=1)[0])\n",
        "        namedict[i]=coname\n",
        "# namedict\n",
        "initdf=df.copy()\n",
        "pxidf = df.rename(columns=namedict)\n",
        "pxidf.head(10)\n",
        "att_orgdf=pd.read_excel(r'data\\Attrition_at_OrgLevel_2020.xlsx')\n",
        "att_orgdf.head() #emp separated\n",
        "# 50000005-sample\n",
        "att_orgdf[att_orgdf[\"Org Unit ID\"]==50000012]\n",
        "att_orgdf_active=pd.read_excel(r'Attrition_Active_Emp.xlsx')\n",
        "att_orgdf_active=att_orgdf_active[att_orgdf_active[\"Year\"]==2020.0]\n",
        "att_orgdf_active[att_orgdf_active[\"Org Unit ID\"]==50000012] # sample org unit\n",
        "print(att_orgdf.shape)\n",
        "att_orgdf_active.columns\n",
        "att_df=pd.read_excel(r'Active_Seprated_Emp_Orglevel_2020.xlsx')\n",
        "att_df.head(10)\n",
        "len(att_df[\"Org Unit ID\"].unique())\n",
        "pxidf=pxidf.dropna()\n",
        "pxidf['Org Unit Number']=pxidf['Org Unit Number'].astype(int)\n",
        "pxidf=pxidf.drop(['Group', 'Group.1', 'Respondents', 'Career Development', 'Culture', \n",
        "                  'Diversity and Inclusion', 'Employee Empowerment Index', 'Employee Engagement', 'Ethics',\n",
        "                  'Supervisor/Employee Interaction','Recipients', 'Response Rate', 'Hierarchy Path'],axis=1)\n",
        "pxidf.head()\n",
        "findf=pd.merge(pxidf,att_df,left_on=\"Org Unit Number\",right_on=\"Org Unit ID\",how='inner')\n",
        "findf.head()\n",
        "print(findf.shape)\n",
        "findf=findf.drop(['Org Unit Number', 'Org Unit' ,'Emp Seperated','Org Unit ID','ActiveEmployees'],axis=1)\n",
        "final_df=findf.copy()\n",
        "final_df.head()\n",
        "def model_dim(X,y):\n",
        "#     xtrain,xtest,ytrain,ytest=train_test_split(X,y,test_size=0.2,random_state=1)\n",
        "    RR=Ridge()\n",
        "    LR=LinearRegression()\n",
        "    models=[]\n",
        "    models.append(('Linear Regression',LR))\n",
        "#     models.append((\"Ridge Regression\",RR))\n",
        "#     print(\"DIMENSION:\",kpi)\n",
        "    dic={}\n",
        "    results=[]\n",
        "    names=[]\n",
        "    for name,model in models:\n",
        "        kfold=model_selection.KFold(n_splits=10,shuffle=True,random_state=0)\n",
        "        cv_result=model_selection.cross_val_score(model,X,y,cv=kfold,scoring='neg_mean_squared_error')\n",
        "        cv_result_acc=model_selection.cross_val_score(model,X,y,cv=kfold,scoring='r2')\n",
        "        results.append(np.sqrt(np.abs(cv_result)))\n",
        "        names.append(name)\n",
        "        BE=np.mean(np.sqrt(np.abs(cv_result)))\n",
        "        VE=np.var(np.sqrt(np.abs(cv_result)))\n",
        "#         print(name)\n",
        "        model.fit(X,y)\n",
        "#         print('\\t\\tTraining Accuracy: ',model.score(xtrain,ytrain))\n",
        "#         print('\\t\\tTesting Accuracy: ',model.score(xtest,ytest))\n",
        "#         print('\\t\\tBias Error: ',BE)\n",
        "#         print('\\t\\tVariance Error: ',VE)\n",
        "#         ypred=model.predict(xtest)\n",
        "#         rmse=np.sqrt(metrics.mean_squared_error(ytest,ypred))\n",
        "#         print('RMSE: ',rmse)\n",
        "        r2=model.score(X,y)\n",
        "        print('R2: ',r2)\n",
        "        adj_r2 = (1 - (1 - r2) * ((X.shape[0] - 1) / \n",
        "                  (X.shape[0] - X.shape[1] - 1)))\n",
        "        print(\"adjusted R2\",adj_r2)\n",
        "#         dic=[kpi,r2,adj_r2]\n",
        "        coeff=pd.Series(model.coef_,X.columns).sort_values(ascending=False)\n",
        "    return(coeff,r2,adj_r2)\n",
        "kpilist=['Career Development', 'Culture', 'Diversity and Inclusion', 'Employee Empowerment Index', 'Employee Engagement', 'Ethics', 'Supervisor/Employee Interaction']\n",
        "y=final_df['AttritionRate']\n",
        "datalist=[]\n",
        "dim_df=pd.DataFrame()\n",
        "for kpi in kpilist:\n",
        "    filter_col = [col for col in final_df if col.startswith(kpi)]\n",
        "    filtered_df=final_df[filter_col]\n",
        "    filtered_df[kpi] = filtered_df.mean(axis=1)\n",
        "    dim_df=pd.concat([filtered_df,dim_df],axis=1)\n",
        "# resdf = pd.DataFrame(datalist, columns = ['Dimension', 'R2 Square','Adjusted R square'])\n",
        "# print(resdf)\n",
        "dim_df=dim_df[kpilist]\n",
        "dim_df.head()\n",
        "final_df=pd.concat([dim_df,y],axis=1)\n",
        "final_df.corr()[\"AttritionRate\"].sort_values(ascending=False)\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "# the independent variables set \n",
        "X = final_df\n",
        "# VIF dataframe \n",
        "vif_data = pd.DataFrame() \n",
        "vif_data[\"feature\"] = X.columns \n",
        "# calculating VIF for each feature \n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) \n",
        "                        for i in range(len(X.columns))] \n",
        "print(vif_data)\n",
        "final_df.corr().head()\n",
        "final_df.head()\n",
        "dim_df.head()\n",
        "# scaling\n",
        "sc=StandardScaler()\n",
        "for i in final_df.columns:\n",
        "    final_df[i]=sc.fit_transform(final_df[[i]])\n",
        "y=final_df['AttritionRate']\n",
        "data,r2,adjr2=model_dim(dim_df,y)\n",
        "data \n",
        "# In[118]:\n",
        "data=data.to_frame().reset_index()\n",
        "data.columns=[\"Dimension\",\"Weightage\"]\n",
        "data[\"R2\"]=r2\n",
        "data[\"Adj R2\"]=adjr2\n",
        "data[\"DataPoints\"]=final_df.shape[0]\n",
        "data.to_csv(\"Results/Attrition_Results.csv\")\n",
        "data #pre\n",
        "filter_col = [col for col in final_df if col.startswith(\"Diversity and Inclusion\")]\n",
        "filtered_df=final_df[filter_col]\n",
        "# the independent variables set \n",
        "X = filtered_df\n",
        "# VIF dataframe \n",
        "vif_data = pd.DataFrame() \n",
        "vif_data[\"feature\"] = X.columns \n",
        "# calculating VIF for each feature \n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) \n",
        "                        for i in range(len(X.columns))] \n",
        "print(vif_data)\n",
        "filtered_df.corr().head()\n",
        "filter_col = [col for col in final_df if col.startswith(\"Culture\")]\n",
        "filtered_df=final_df[filter_col]\n",
        "# the independent variables set \n",
        "X = filtered_df\n",
        "# VIF dataframe \n",
        "vif_data = pd.DataFrame() \n",
        "vif_data[\"feature\"] = X.columns \n",
        "# calculating VIF for each feature \n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) \n",
        "                        for i in range(len(X.columns))] \n",
        "print(vif_data)\n",
        "filtered_df.corr().head()\n",
        "final_df.shape\n",
        "len(final_df[final_df[\"AttritionRate\"]==0.0])\n",
        "final_df.columns\n",
        "import seaborn as sns\n",
        "sns.kdeplot(y)\n",
        "(final_df.corr()['AttritionRate']).sort_values(ascending=False)\n",
        "# In[70]:\n",
        "def model_dim(X,y,kpi):\n",
        "#     xtrain,xtest,ytrain,ytest=train_test_split(X,y,test_size=0.2,random_state=1)\n",
        "    RR=Ridge()\n",
        "    LR=LinearRegression()\n",
        "    models=[]\n",
        "    models.append(('Linear Regression',LR))\n",
        "    models.append((\"Ridge Regression\",RR))\n",
        "    print(\"DIMENSION:\",kpi)\n",
        "    dic={}\n",
        "    results=[]\n",
        "    names=[]\n",
        "    for name,model in models:\n",
        "        kfold=model_selection.KFold(n_splits=10,shuffle=True,random_state=0)\n",
        "        cv_result=model_selection.cross_val_score(model,X,y,cv=kfold,scoring='neg_mean_squared_error')\n",
        "        cv_result_acc=model_selection.cross_val_score(model,X,y,cv=kfold,scoring='r2')\n",
        "        results.append(np.sqrt(np.abs(cv_result)))\n",
        "        names.append(name)\n",
        "        BE=np.mean(np.sqrt(np.abs(cv_result)))\n",
        "        VE=np.var(np.sqrt(np.abs(cv_result)))\n",
        "        print(name)\n",
        "model.fit(X,y)\n",
        "#         print('\\t\\tTraining Accuracy: ',model.score(xtrain,ytrain))\n",
        "#         print('\\t\\tTesting Accuracy: ',model.score(xtest,ytest))\n",
        "#         print('\\t\\tBias Error: ',BE)\n",
        "#         print('\\t\\tVariance Error: ',VE)\n",
        "#         ypred=model.predict(xtest)\n",
        "#         rmse=np.sqrt(metrics.mean_squared_error(ytest,ypred))\n",
        "#         print('RMSE: ',rmse)\n",
        "        r2=model.score(X,y)\n",
        "        print('R2: ',r2)\n",
        "        adj_r2 = (1 - (1 - r2) * ((X.shape[0] - 1) / \n",
        "                  (X.shape[0] - X.shape[1] - 1)))\n",
        "        print(\"adjusted R2\",adj_r2)\n",
        "        dic=[kpi,r2,adj_r2]\n",
        "#         LR.fit(xtrain,ytrain)\n",
        "#         LR.coef_\n",
        "#         pd.Series(LR.coef_,X.columns).sort_values(ascending=False)\n",
        "    return(dic)\n",
        "kpilist=['Career Development', 'Culture', 'Diversity and Inclusion', 'Employee Empowerment Index', 'Employee Engagement', 'Ethics', 'Supervisor/Employee Interaction']\n",
        "y=final_df['AttritionRate']\n",
        "datalist=[]\n",
        "for kpi in kpilist:\n",
        "    filter_col = [col for col in final_df if col.startswith(kpi)]\n",
        "    filtered_df=final_df[filter_col]\n",
        "    kpidict={}\n",
        "    data=model_dim(filtered_df,y,kpi)\n",
        "    datalist.append(data)\n",
        "    print(\"--------\\n\")\n",
        "resdf = pd.DataFrame(datalist, columns = ['Dimension', 'R2 Square','Adjusted R square'])\n",
        "print(resdf)\n",
        "resdf.to_csv(\"Attrition_Reg_Results.csv\")\n",
        "final_df.head()\n",
        "final_df.drop([\"AttritionRate\"],axis=1,inplace=True)\n",
        "def attbin(att):\n",
        "    if(att>0.0):\n",
        "        s=1\n",
        "    else:\n",
        "        s=0\n",
        "    return s\n",
        "final_df[\"Attbin\"]=final_df.apply(lambda x:attbin(x[\"AttritionRate\"]),axis=1)\n",
        "final_df.head()\n",
        "# In[118]:\n",
        "filtered_df['mean'] = filtered_df.mean(axis=1)\n",
        "filtered_df.head()\n",
        "# In[121]:\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "# kpilist=['Employee Engagement']\n",
        "y=final_df['Attbin']\n",
        "kpilist=['Career Development', 'Culture', 'Diversity and Inclusion', 'Employee Empowerment Index', 'Employee Engagement', 'Ethics', 'Supervisor/Employee Interaction']\n",
        "datalist=[]\n",
        "for kpi in kpilist:\n",
        "    filter_col = [col for col in final_df if col.startswith(kpi)]\n",
        "    filtered_df=final_df[filter_col]\n",
        "    filtered_df['mean'] = filtered_df.mean(axis=1)\n",
        "    filtered_df=filtered_df[['mean']]\n",
        "    model = sm.Logit(y, filtered_df)\n",
        "    result = model.fit(method='newton')\n",
        "    print(kpi)\n",
        "    print(result.summary())\n",
        "def model_dim(X,y,kpi):\n",
        "    xtrain,xtest,ytrain,ytest=train_test_split(X,y,test_size=0.2,random_state=1)\n",
        "    LR=LinearRegression()\n",
        "    RR=Ridge()\n",
        "    models=[]\n",
        "#     models.append(('Linear Regression',LR))\n",
        "    models.append((\"Ridge Regression\",RR))\n",
        "    dic={}\n",
        "    results=[]\n",
        "    names=[]\n",
        "    for name,model in models:\n",
        "        kfold=model_selection.KFold(n_splits=10,shuffle=True,random_state=0)\n",
        "        cv_result=model_selection.cross_val_score(model,X,y,cv=kfold,scoring='neg_mean_squared_error')\n",
        "        cv_result_acc=model_selection.cross_val_score(model,X,y,cv=kfold,scoring='r2')\n",
        "        results.append(np.sqrt(np.abs(cv_result)))\n",
        "        names.append(name)\n",
        "        BE=np.mean(np.sqrt(np.abs(cv_result)))\n",
        "        VE=np.var(np.sqrt(np.abs(cv_result)))\n",
        "        print(name)\n",
        "        model.fit(xtrain,ytrain)\n",
        "        print('\\t\\tTraining Accuracy: ',model.score(xtrain,ytrain))\n",
        "        print('\\t\\tTesting Accuracy: ',model.score(xtest,ytest))\n",
        "#         print('\\t\\tBias Error: ',BE)\n",
        "#         print('\\t\\tVariance Error: ',VE)\n",
        "        ypred=model.predict(xtest)\n",
        "        rmse=np.sqrt(metrics.mean_squared_error(ytest,ypred))\n",
        "        print(\"DIMENSION:\",kpi)\n",
        "        r2=model.score(X,y)\n",
        "        print('R2: ',r2)\n",
        "        adj_r2 = (1 - (1 - r2) * ((X.shape[0] - 1) / \n",
        "                  (X.shape[0] - X.shape[1] - 1)))\n",
        "        print(\"adjusted R2\",adj_r2)\n",
        "        dic=[kpi,r2,adj_r2]\n",
        "#         LR.fit(xtrain,ytrain)\n",
        "#         LR.coef_\n",
        "#         pd.Series(LR.coef_,X.columns).sort_values(ascending=False)\n",
        "    return(dic)\n",
        "#     LR.fit(xtrain,ytrain)\n",
        "#     LR.coef_\n",
        "#     pd.Series(LR.coef_,X.columns).sort_values(ascending=False)\n",
        "# In[78]:\n",
        "datalist=[]\n",
        "for kpi in kpilist:\n",
        "    filter_col = [col for col in final_df if col.startswith(kpi)]\n",
        "    filtered_df=final_df[filter_col]\n",
        "    kpidict={}\n",
        "    data=model_dim(filtered_df,y,kpi)\n",
        "    datalist.append(data)\n",
        "    print(\"--------\\n\")\n",
        "resdf = pd.DataFrame(datalist, columns = ['Dimension', 'R2 Square','Adjusted R square'])\n",
        "print(resdf)\n",
        "# In[37]:\n",
        "def model_dim(X,y,kpi):\n",
        "    xtrain,xtest,ytrain,ytest=train_test_split(X,y,test_size=0.2,random_state=1)\n",
        "    LR=LinearRegression()\n",
        "    RR=Ridge()\n",
        "    models=[]\n",
        "#     models.append(('Linear Regression',LR))\n",
        "    models.append((\"Ridge Regression\",RR))\n",
        "    print(\"DIMENSION:\",kpi)\n",
        "    dic={}\n",
        "    results=[]\n",
        "    names=[]\n",
        "    for name,model in models:\n",
        "        kfold=model_selection.KFold(n_splits=10,shuffle=True,random_state=0)\n",
        "        cv_result=model_selection.cross_val_score(model,X,y,cv=kfold,scoring='neg_mean_squared_error')\n",
        "        cv_result_acc=model_selection.cross_val_score(model,X,y,cv=kfold,scoring='r2')\n",
        "        results.append(np.sqrt(np.abs(cv_result)))\n",
        "        names.append(name)\n",
        "        BE=np.mean(np.sqrt(np.abs(cv_result)))\n",
        "        VE=np.var(np.sqrt(np.abs(cv_result)))\n",
        "        print(name)\n",
        "        model.fit(xtrain,ytrain)\n",
        "        print('\\t\\tTraining Accuracy: ',model.score(xtrain,ytrain))\n",
        "        print('\\t\\tTesting Accuracy: ',model.score(xtest,ytest))\n",
        "#         print('\\t\\tBias Error: ',BE)\n",
        "#         print('\\t\\tVariance Error: ',VE)\n",
        "        ypred=model.predict(xtest)\n",
        "        rmse=np.sqrt(metrics.mean_squared_error(ytest,ypred))\n",
        "        print('RMSE: ',rmse)\n",
        "        r2=model.score(xtrain,ytrain)\n",
        "        print('R2: ',r2)\n",
        "        adj_r2 = (1 - (1 - r2) * ((xtrain.shape[0] - 1) / \n",
        "                  (xtrain.shape[0] - xtrain.shape[1] - 1)))\n",
        "        print(\"adjusted R2\",adj_r2)\n",
        "        dic={\"rmse\":rmse,\"R2 square\":r2,\"Adjusted R2\":adj_r2}\n",
        "    return(dic)\n",
        "#     LR.fit(xtrain,ytrain)\n",
        "#     LR.coef_\n",
        "#     pd.Series(LR.coef_,X.columns).sort_values(ascending=False)\n",
        "kpilist=['Career Development', 'Culture', 'Diversity and Inclusion', 'Employee Empowerment Index', 'Employee Engagement', 'Ethics', 'Supervisor/Employee Interaction']\n",
        "y=final_df['AttritionRate']\n",
        "for kpi in kpilist:\n",
        "    filter_col = [col for col in final_df if col.startswith(kpi)]\n",
        "    filtered_df=final_df[filter_col]\n",
        "    kpidict={}\n",
        "    kpidict[kpi]=model_dim(filtered_df,y,kpi)\n",
        "    print(kpidict)\n",
        "    print(\"----------------\\n\")\n",
        "X=final_df.drop('AttritionRate',axis=1)\n",
        "y=final_df['AttritionRate']\n",
        "X.head()\n",
        "kpilist=['Employee Engagement']\n",
        "for kpi in kpilist:\n",
        "    filter_col = [col for col in final_df if col.startswith(kpi)]\n",
        "    filtered_df=final_df[filter_col]\n",
        "X=filtered_df\n",
        "X.shape\n",
        "xtrain,xtest,ytrain,ytest=train_test_split(X,y,test_size=0.2,random_state=1)\n",
        "LR=LinearRegression()\n",
        "models=[]\n",
        "models.append(('Linear Regression',LR))\n",
        "results=[]\n",
        "names=[]\n",
        "for name,model in models:\n",
        "    kfold=model_selection.KFold(n_splits=10,shuffle=True,random_state=0)\n",
        "    cv_result=model_selection.cross_val_score(model,X,y,cv=kfold,scoring='neg_mean_squared_error')\n",
        "    cv_result_acc=model_selection.cross_val_score(model,X,y,cv=kfold,scoring='r2')\n",
        "    results.append(np.sqrt(np.abs(cv_result)))\n",
        "    names.append(name)\n",
        "    BE=np.mean(np.sqrt(np.abs(cv_result)))\n",
        "    VE=np.var(np.sqrt(np.abs(cv_result)))\n",
        "    print(name)\n",
        "    model.fit(xtrain,ytrain)\n",
        "    print('\\t\\tTraining Accuracy: ',model.score(xtrain,ytrain))\n",
        "    print('\\t\\tTesting Accuracy: ',model.score(xtest,ytest))\n",
        "    print('\\t\\tBias Error: ',BE)\n",
        "    print('\\t\\tVariance Error: ',VE)\n",
        "LR.fit(xtrain,ytrain)\n",
        "LR.coef_\n",
        "pd.Series(LR.coef_,X.columns).sort_values(ascending=False)\n",
        "ypred=model.predict(xtest)\n",
        "rmse=np.sqrt(metrics.mean_squared_error(ytest,ypred))\n",
        "print('RMSE: ',rmse)\n",
        "r2=model.score(xtrain,ytrain)\n",
        "print('R2: ',r2)\n",
        "adj_r2 = (1 - (1 - r2) * ((xtrain.shape[0] - 1) / \n",
        "          (xtrain.shape[0] - xtrain.shape[1] - 1)))\n",
        "print(\"adjR2\",adj_r2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lM1pr5zYO2On"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}